name: build

on:
  pull_request:
    paths:
      - '**'

  push:
    paths:
      - '**'
      - '!docs/**'
      - '!contrib/**'
  
env:
  DOCKER_USER: gadockersvc
  DOCKER_IMAGE: opendatacube/datacube-tests:latest1.9
  # NB Restore standard image name when merge into develop
  # DOCKER_IMAGE: opendatacube/datacube-tests:latest


jobs:
  main:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - uses: dorny/paths-filter@v2
      id: changes
      if: |
        github.event_name == 'push'
      with:
        filters: |
          docker:
            - 'docker/**'

    - name: Pull Docker
      if: steps.changes.outputs.docker == 'false'
      run: |
        docker pull "${{ env.DOCKER_IMAGE }}"

    - name: Set up Docker Buildx
      if: steps.changes.outputs.docker == 'true'
      uses: docker/setup-buildx-action@v2

    - name: Cache Docker layers
      if: steps.changes.outputs.docker == 'true'
      uses: pat-s/always-upload-cache@v3.0.11
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: DockerHub Login
      id: login
      if: |
        github.event_name == 'push'
        && github.ref == 'refs/heads/develop'
      uses: docker/login-action@v2
      with:
        username: ${{ env.DOCKER_USER }}
        password: ${{ secrets.GADOCKERSVC_PASSWORD }}

    - name: Build Docker
      uses: docker/build-push-action@v4
      with:
        file: docker/Dockerfile
        context: .
        tags: ${{ env.DOCKER_IMAGE }}
        load: true

    - name: Verify and Run Tests
      run: |
        echo "Verify that twine is installed"
        docker run --rm opendatacube/datacube-tests:latest twine --version

        echo "Run tests"
        cat <<EOF | docker run --rm -i -v $(pwd):/code ${{ env.DOCKER_IMAGE }} bash -
          pip install -e /code/tests/drivers/fail_drivers --no-deps
          pip install -e /code/examples/io_plugin --no-deps

          pytest -r a \
            --cov datacube \
            --cov-report=xml \
            --doctest-ignore-import-errors \
            --durations=5 \
            datacube \
            tests \
            integration_tests
        EOF

    - name: DockerHub Push
      if: |
        github.event_name == 'push'
        && github.ref == 'refs/heads/develop'
        && steps.changes.outputs.docker == 'true'
      uses: docker/build-push-action@v4
      with:
        file: docker/Dockerfile
        context: .
        push: true
        tags: ${{env.DOCKER_IMAGE}}

    - name: Build Packages
      run: |
        cat <<EOF | docker run --rm -i  \
                  -v $(pwd):/code \
                  -e SKIP_DB=yes \
                  ${{ env.DOCKER_IMAGE }} bash -
        python setup.py bdist_wheel sdist
        ls -lh ./dist/
        twine check ./dist/*
        EOF

    - name: Publish to PyPi
      if: |
        github.event_name == 'push'
        && github.ref == 'refs/heads/pypi/publish'
      run: |
        if [ -n "${TWINE_PASSWORD}" ]; then
          docker run --rm  \
            -v $(pwd):/code \
            -e SKIP_DB=yes \
            ${{ env.DOCKER_IMAGE }} \
            twine upload \
              --verbose \
              --non-interactive \
              --disable-progress-bar \
              --username=__token__ \
              --password=${TWINE_PASSWORD} \
              --skip-existing dist/*
        else
           echo "Skipping upload as 'PyPiToken' is not set"
        fi

      env:
        TWINE_PASSWORD: ${{ secrets.PyPiToken }}

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
